import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import hashlib
import os
import plotly.express as px


# ================================
# Streamlit è¨­å®š
# ================================
st.set_page_config(page_title="MLBæ€ªæˆ‘åˆ†æï¼ˆPlotlyç‰ˆï¼‰", layout="wide")
st.title("âš¾ MLBæ€ªæˆ‘åˆ†æãƒ„ãƒ¼ãƒ« Bç‰ˆï¼ˆPlotlyè‰²ä»˜ããƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ãƒ»æ”¹å–„ç‰ˆï¼‰")

DATA_CSV = "injury_data.csv"
HASH_FILE = "html_hash.txt"

# ================================
# ãƒãƒ¼ãƒ ãƒãƒƒãƒ—
# ================================
team_map = {
    "Arizona Diamondbacks": "Arizona",
    "Atlanta Braves": "Atlanta",
    "Baltimore Orioles": "Baltimore",
    "Boston Red Sox": "Boston",
    "Chicago Cubs": "Chi. Cubs",
    "Chicago White Sox": "Chi. White Sox",
    "Cincinnati Reds": "Cincinnati",
    "Cleveland Guardians": "Cleveland",
    "Colorado Rockies": "Colorado",
    "Detroit Tigers": "Detroit",
    "Houston Astros": "Houston",
    "Kansas City Royals": "Kansas City",
    "Los Angeles Angels": "L.A. Angels",
    "Los Angeles Dodgers": "L.A. Dodgers",
    "Miami Marlins": "Miami",
    "Milwaukee Brewers": "Milwaukee",
    "Minnesota Twins": "Minnesota",
    "New York Mets": "N.Y. Mets",
    "New York Yankees": "N.Y. Yankees",
    "Oakland Athletics": "Athletics",
    "Philadelphia Phillies": "Philadelphia",
    "Pittsburgh Pirates": "Pittsburgh",
    "San Diego Padres": "San Diego",
    "San Francisco Giants": "San Francisco",
    "Seattle Mariners": "Seattle",
    "St. Louis Cardinals": "St. Louis",
    "Tampa Bay Rays": "Tampa Bay",
    "Texas Rangers": "Texas",
    "Toronto Blue Jays": "Toronto",
    "Washington Nationals": "Washington"
}

reverse_map = {v: k for k, v in team_map.items()}

# ================================
# ãƒãƒƒã‚·ãƒ¥å‡¦ç†
# ================================
def get_html_hash(text):
    return hashlib.md5(text.encode("utf-8")).hexdigest()

def save_hash(hash_value):
    with open(HASH_FILE, "w") as f:
        f.write(hash_value)

def load_hash():
    if not os.path.exists(HASH_FILE):
        return None
    return open(HASH_FILE).read().strip()

# ================================
# CSV èª­ã¿è¾¼ã¿
# ================================
def load_data_from_csv():
    if not os.path.exists(DATA_CSV):
        return None
    return pd.read_csv(DATA_CSV)

# ================================
# ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
# ================================
def scrape_injury_data():
    url = "https://www.cbssports.com/mlb/injuries/"
    html = requests.get(url).text
    soup = BeautifulSoup(html, "html.parser")
    tables = pd.read_html(url)

    team_names = [h4.get_text(strip=True) for h4 in soup.find_all("h4")]

    all_records = []
    for team_short, df_tmp in zip(team_names, tables):
        full_name = None
        for full, short in team_map.items():
            if short == team_short:
                full_name = full

        df_tmp["TEAM"] = full_name
        all_records.append(df_tmp)

    df = pd.concat(all_records, ignore_index=True)

    df.to_csv(DATA_CSV, index=False)
    save_hash(get_html_hash(html))
    return df

# ================================
# ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼ˆæ›´æ–°æ¤œçŸ¥ & ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼‰
# ================================
def fetch_injury_data(force_update=False):
    url = "https://www.cbssports.com/mlb/injuries/"

    if force_update:
        st.warning("ğŸ”„ æ‰‹å‹•æ›´æ–°ï¼šæœ€æ–°ãƒ‡ãƒ¼ã‚¿å–å¾—ä¸­â€¦")
        return scrape_injury_data()

    html = requests.get(url).text
    current_hash = get_html_hash(html)
    old_hash = load_hash()

    if os.path.exists(DATA_CSV) and current_hash == old_hash:
        st.info("âœ” ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ä½¿ç”¨ï¼ˆHTMLå¤‰æ›´ãªã—ï¼‰")
        return load_data_from_csv()

    st.warning("ğŸ”„ ãƒ‡ãƒ¼ã‚¿æ›´æ–°ã‚’æ¤œçŸ¥ â†’ æœ€æ–°ãƒ‡ãƒ¼ã‚¿å–å¾—")
    return scrape_injury_data()

# ================================
# åˆ†é¡å‡¦ç†
# ================================
def classify_player(pos):
    if isinstance(pos, str) and any(p in pos for p in ["SP", "RP", "P"]):
        return "Pitcher"
    return "Fielder"

def extract_injury_part(text):
    if not isinstance(text, str):
        return "ãã®ä»–"

    keywords = {
        "è‚˜": ["elbow"],
        "è‚©": ["shoulder"],
        "è†": ["knee"],
        "èƒŒä¸­": ["back"],
        "å‰è…•": ["forearm"],
        "æ‰‹é¦–": ["wrist"],
        "è‚¡é–¢ç¯€": ["hip"],
        "ãƒãƒ ã‚¹ãƒˆãƒªãƒ³ã‚°": ["hamstring"],
        "è…¹éƒ¨": ["abdomen"],
        "æŒ‡": ["finger"],
        "æ‰‹": ["hand"]
    }

    t = text.lower()
    for jp, keys in keywords.items():
        if any(k in t for k in keys):
            return jp

    return "ãã®ä»–"

# ================================
# Pivotä½œæˆ
# ================================
def create_pivot(df):
    df["TeamFull"] = df["TEAM"]

    pivot = df.pivot_table(
        index="TeamFull",
        columns="injury_part_jp",
        values="Player",
        aggfunc="count",
        fill_value=0
    )

    pivot = pivot.reindex(list(team_map.keys()), fill_value=0)
    pivot = pivot[pivot.sum().sort_values(ascending=False).index]

    return pivot

# ================================
# Plotly è‰²ä»˜ããƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—
# ================================
def plotly_heatmap(pivot, title, colorscale):
    st.subheader(title)

    fig = px.imshow(
        pivot,
        text_auto=True,
        aspect="auto",
        color_continuous_scale=colorscale,
        labels=dict(color="äººæ•°"),
        zmin=0,
        zmax=pivot.values.max(),
    )

    # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆå¯¾å¿œ + ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆèª¿æ•´
    fig.update_layout(
        xaxis_title="æ€ªæˆ‘éƒ¨ä½",
        yaxis_title="ãƒãƒ¼ãƒ å",
        font=dict(size=14, family="Arial, Yu Gothic, Hiragino Sans"),
        height=900,
        margin=dict(l=40, r=40, t=40, b=40),
    )

    fig.update_xaxes(
        side="top"
    )
    st.plotly_chart(fig, use_container_width=True)





# ================================
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ================================
force_update = st.button("ğŸ”„ æ‰‹å‹•æ›´æ–°ï¼ˆæœ€æ–°ãƒ‡ãƒ¼ã‚¿å–å¾—ï¼‰")

st.markdown(
    """
    <div style="font-size: 12px; color: gray; margin-top: -6px; padding-bottom: 20px;">
    â€» ãƒ‡ãƒ¼ã‚¿å–å¾—å…ƒï¼š
    <a href="https://www.cbssports.com/mlb/injuries/" target="_blank">
    CBS Sports â€“ MLB Injuries
    </a>
    </div>
    """,
    unsafe_allow_html=True
)

st.sidebar.markdown(
    """
    â€» æœ¬ã‚¢ãƒ—ãƒªã¯å…¬é–‹æƒ…å ±ã‚’ã‚‚ã¨ã«ã—ãŸåˆ†æãƒ»å¯è¦–åŒ–ãƒ„ãƒ¼ãƒ«ã§ã™ã€‚  
    ãƒ‡ãƒ¼ã‚¿ã®æ­£ç¢ºæ€§ãƒ»å®Œå…¨æ€§ã‚’ä¿è¨¼ã™ã‚‹ã‚‚ã®ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚
    """
)

df = fetch_injury_data(force_update)

df["PlayerType"] = df["Position"].apply(classify_player)
df["injury_part_jp"] = df["Injury"].apply(extract_injury_part)

pitcher_df = df[df["PlayerType"] == "Pitcher"]
fielder_df = df[df["PlayerType"] == "Fielder"]

pivot_pitcher = create_pivot(pitcher_df)
pivot_fielder = create_pivot(fielder_df)

# ================================
# è¡¨ç¤ºï¼ˆæŠ•æ‰‹ï¼šèµ¤ / é‡æ‰‹ï¼šé’ï¼‰
# ================================
plotly_heatmap(pivot_pitcher, "ğŸ”´ æŠ•æ‰‹ã®ãƒãƒ¼ãƒ åˆ¥æ€ªæˆ‘äººæ•°", "Reds")
plotly_heatmap(pivot_fielder, "ğŸ”µ é‡æ‰‹ã®ãƒãƒ¼ãƒ åˆ¥æ€ªæˆ‘äººæ•°", "Blues")

